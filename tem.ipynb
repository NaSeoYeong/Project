{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# df = pd.read_csv('./data/405957090_5천만건(hum,voc포함).csv')\n",
    "\n",
    "# df[\"updated\"] = pd.to_datetime(df[\"updated\"])\n",
    "# df=df.sort_values(\"updated\")\n",
    "\n",
    "# # -1이 있는 행을 삭제\n",
    "# df = df.replace(-1, np.nan)  # -1을 NaN으로 변경\n",
    "# df = df.dropna()  # NaN이 있는 행 삭제\n",
    "\n",
    "# # 온도가 1500 이상 4500 이하인 데이터만 선택\n",
    "# df = df[(df['temperature'] >= 1500) & (df['temperature'] <= 4500)]\n",
    "\n",
    "# # 날짜 정상 데이터 선택\n",
    "# df = df[(df['days'] > 0) & (df['days'] <= 1800)]\n",
    "\n",
    "# # 성별 정상 데이터 선택\n",
    "# df = df[df[\"sex\"]!=-1]\n",
    "\n",
    "\n",
    "# d1=[2179,1766,2220,1970,1702,2411,357,2552,2273,1416]\n",
    "\n",
    "# df = df[df['device_id'].isin(d1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2220, 1416)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# age_min = df['days'].min()\n",
    "# age_max = df['days'].max()\n",
    "\n",
    "# min_device_id = df[df['days']==age_min]['device_id'].iloc[0]\n",
    "# max_device_id = df[df['days']==age_max]['device_id'].iloc[0]\n",
    "\n",
    "# min_device_id, max_device_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yeong\\AppData\\Local\\Temp\\ipykernel_8648\\3106642965.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  day_df['tem_bfill'] = day_df['tem'].bfill()\n",
      "c:\\Users\\yeong\\miniconda3\\envs\\monit\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\yeong\\miniconda3\\envs\\monit\\lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\yeong\\AppData\\Local\\Temp\\ipykernel_8648\\3106642965.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  day_df['sensor_mean'] = sensor_mean * len(day_df)\n",
      "C:\\Users\\yeong\\AppData\\Local\\Temp\\ipykernel_8648\\3106642965.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  day_df['hub_mean'] = hub_mean * len(day_df)\n",
      "C:\\Users\\yeong\\AppData\\Local\\Temp\\ipykernel_8648\\3106642965.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  day_df.drop(['device_id', 'days','sex','temperature','humidity','voc','hum','tem'], axis=1, inplace=True)\n",
      "C:\\Users\\yeong\\AppData\\Local\\Temp\\ipykernel_8648\\3106642965.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  day_df['tem_bfill'] = day_df['tem'].bfill()\n",
      "c:\\Users\\yeong\\miniconda3\\envs\\monit\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\yeong\\miniconda3\\envs\\monit\\lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\yeong\\AppData\\Local\\Temp\\ipykernel_8648\\3106642965.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  day_df['sensor_mean'] = sensor_mean * len(day_df)\n",
      "C:\\Users\\yeong\\AppData\\Local\\Temp\\ipykernel_8648\\3106642965.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  day_df['hub_mean'] = hub_mean * len(day_df)\n",
      "C:\\Users\\yeong\\AppData\\Local\\Temp\\ipykernel_8648\\3106642965.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  day_df.drop(['device_id', 'days','sex','temperature','humidity','voc','hum','tem'], axis=1, inplace=True)\n",
      "C:\\Users\\yeong\\AppData\\Local\\Temp\\ipykernel_8648\\3106642965.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  day_df['tem_bfill'] = day_df['tem'].bfill()\n",
      "c:\\Users\\yeong\\miniconda3\\envs\\monit\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\yeong\\miniconda3\\envs\\monit\\lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\yeong\\AppData\\Local\\Temp\\ipykernel_8648\\3106642965.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  day_df['sensor_mean'] = sensor_mean * len(day_df)\n",
      "C:\\Users\\yeong\\AppData\\Local\\Temp\\ipykernel_8648\\3106642965.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  day_df['hub_mean'] = hub_mean * len(day_df)\n",
      "C:\\Users\\yeong\\AppData\\Local\\Temp\\ipykernel_8648\\3106642965.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  day_df.drop(['device_id', 'days','sex','temperature','humidity','voc','hum','tem'], axis=1, inplace=True)\n",
      "C:\\Users\\yeong\\AppData\\Local\\Temp\\ipykernel_8648\\3106642965.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  day_df['tem_bfill'] = day_df['tem'].bfill()\n",
      "c:\\Users\\yeong\\miniconda3\\envs\\monit\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\yeong\\miniconda3\\envs\\monit\\lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\yeong\\AppData\\Local\\Temp\\ipykernel_8648\\3106642965.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  day_df['sensor_mean'] = sensor_mean * len(day_df)\n",
      "C:\\Users\\yeong\\AppData\\Local\\Temp\\ipykernel_8648\\3106642965.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  day_df['hub_mean'] = hub_mean * len(day_df)\n",
      "C:\\Users\\yeong\\AppData\\Local\\Temp\\ipykernel_8648\\3106642965.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  day_df.drop(['device_id', 'days','sex','temperature','humidity','voc','hum','tem'], axis=1, inplace=True)\n",
      "C:\\Users\\yeong\\AppData\\Local\\Temp\\ipykernel_8648\\3106642965.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  day_df['tem_bfill'] = day_df['tem'].bfill()\n",
      "c:\\Users\\yeong\\miniconda3\\envs\\monit\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\yeong\\miniconda3\\envs\\monit\\lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\yeong\\AppData\\Local\\Temp\\ipykernel_8648\\3106642965.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  day_df['sensor_mean'] = sensor_mean * len(day_df)\n",
      "C:\\Users\\yeong\\AppData\\Local\\Temp\\ipykernel_8648\\3106642965.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  day_df['hub_mean'] = hub_mean * len(day_df)\n",
      "C:\\Users\\yeong\\AppData\\Local\\Temp\\ipykernel_8648\\3106642965.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  day_df.drop(['device_id', 'days','sex','temperature','humidity','voc','hum','tem'], axis=1, inplace=True)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 4.58 GiB for an array with shape (38, 16188570) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\yeong\\Desktop\\Project\\tem.ipynb 셀 4\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yeong/Desktop/Project/tem.ipynb#W4sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     _df[\u001b[39m'\u001b[39m\u001b[39mtem_moving_avg\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m _df[\u001b[39m'\u001b[39m\u001b[39mtem_bfill\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mrolling(window\u001b[39m=\u001b[39m\u001b[39m1200\u001b[39m)\u001b[39m.\u001b[39mmean()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yeong/Desktop/Project/tem.ipynb#W4sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _df\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/yeong/Desktop/Project/tem.ipynb#W4sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m df_357_after \u001b[39m=\u001b[39m make_df(df_357)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yeong/Desktop/Project/tem.ipynb#W4sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m df_357_after\n",
      "\u001b[1;32mc:\\Users\\yeong\\Desktop\\Project\\tem.ipynb 셀 4\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yeong/Desktop/Project/tem.ipynb#W4sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     day_df\u001b[39m.\u001b[39mdrop([\u001b[39m'\u001b[39m\u001b[39mdevice_id\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdays\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39msex\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mtemperature\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mhumidity\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mvoc\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mhum\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mtem\u001b[39m\u001b[39m'\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yeong/Desktop/Project/tem.ipynb#W4sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     \u001b[39m# 원본 데이터와 concat\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/yeong/Desktop/Project/tem.ipynb#W4sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     _df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mmerge(_df, day_df, how\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mleft\u001b[39;49m\u001b[39m'\u001b[39;49m, on\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mupdated\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yeong/Desktop/Project/tem.ipynb#W4sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39m# 인덱스 설정\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yeong/Desktop/Project/tem.ipynb#W4sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m _df\u001b[39m.\u001b[39mset_index(\u001b[39m'\u001b[39m\u001b[39mupdated\u001b[39m\u001b[39m'\u001b[39m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\yeong\\miniconda3\\envs\\monit\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:183\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    169\u001b[0m     op \u001b[39m=\u001b[39m _MergeOperation(\n\u001b[0;32m    170\u001b[0m         left_df,\n\u001b[0;32m    171\u001b[0m         right_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    181\u001b[0m         validate\u001b[39m=\u001b[39mvalidate,\n\u001b[0;32m    182\u001b[0m     )\n\u001b[1;32m--> 183\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result(copy\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[1;32mc:\\Users\\yeong\\miniconda3\\envs\\monit\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:885\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    881\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indicator_pre_merge(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright)\n\u001b[0;32m    883\u001b[0m join_index, left_indexer, right_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_join_info()\n\u001b[1;32m--> 885\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reindex_and_concat(\n\u001b[0;32m    886\u001b[0m     join_index, left_indexer, right_indexer, copy\u001b[39m=\u001b[39;49mcopy\n\u001b[0;32m    887\u001b[0m )\n\u001b[0;32m    888\u001b[0m result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_type)\n\u001b[0;32m    890\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindicator:\n",
      "File \u001b[1;32mc:\\Users\\yeong\\miniconda3\\envs\\monit\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:876\u001b[0m, in \u001b[0;36m_MergeOperation._reindex_and_concat\u001b[1;34m(self, join_index, left_indexer, right_indexer, copy)\u001b[0m\n\u001b[0;32m    874\u001b[0m left\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m llabels\n\u001b[0;32m    875\u001b[0m right\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m rlabels\n\u001b[1;32m--> 876\u001b[0m result \u001b[39m=\u001b[39m concat([left, right], axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m    877\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\yeong\\miniconda3\\envs\\monit\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:393\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    378\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    380\u001b[0m op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[0;32m    381\u001b[0m     objs,\n\u001b[0;32m    382\u001b[0m     axis\u001b[39m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m     sort\u001b[39m=\u001b[39msort,\n\u001b[0;32m    391\u001b[0m )\n\u001b[1;32m--> 393\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result()\n",
      "File \u001b[1;32mc:\\Users\\yeong\\miniconda3\\envs\\monit\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:680\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m             indexers[ax] \u001b[39m=\u001b[39m obj_labels\u001b[39m.\u001b[39mget_indexer(new_labels)\n\u001b[0;32m    678\u001b[0m     mgrs_indexers\u001b[39m.\u001b[39mappend((obj\u001b[39m.\u001b[39m_mgr, indexers))\n\u001b[1;32m--> 680\u001b[0m new_data \u001b[39m=\u001b[39m concatenate_managers(\n\u001b[0;32m    681\u001b[0m     mgrs_indexers, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnew_axes, concat_axis\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbm_axis, copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy\n\u001b[0;32m    682\u001b[0m )\n\u001b[0;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    684\u001b[0m     new_data\u001b[39m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[1;32mc:\\Users\\yeong\\miniconda3\\envs\\monit\\lib\\site-packages\\pandas\\core\\internals\\concat.py:131\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[39m# Assertions disabled for performance\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[39m# for tup in mgrs_indexers:\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[39m#    # caller is responsible for ensuring this\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[39m#    indexers = tup[1]\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[39m#    assert concat_axis not in indexers\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[39mif\u001b[39;00m concat_axis \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 131\u001b[0m     mgrs \u001b[39m=\u001b[39m _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)\n\u001b[0;32m    132\u001b[0m     \u001b[39mreturn\u001b[39;00m mgrs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mconcat_horizontal(mgrs, axes)\n\u001b[0;32m    134\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mgrs_indexers) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m mgrs_indexers[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mnblocks \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\yeong\\miniconda3\\envs\\monit\\lib\\site-packages\\pandas\\core\\internals\\concat.py:230\u001b[0m, in \u001b[0;36m_maybe_reindex_columns_na_proxy\u001b[1;34m(axes, mgrs_indexers, needs_copy)\u001b[0m\n\u001b[0;32m    220\u001b[0m         mgr \u001b[39m=\u001b[39m mgr\u001b[39m.\u001b[39mreindex_indexer(\n\u001b[0;32m    221\u001b[0m             axes[i],\n\u001b[0;32m    222\u001b[0m             indexers[i],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    227\u001b[0m             use_na_proxy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,  \u001b[39m# only relevant for i==0\u001b[39;00m\n\u001b[0;32m    228\u001b[0m         )\n\u001b[0;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m needs_copy \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m indexers:\n\u001b[1;32m--> 230\u001b[0m         mgr \u001b[39m=\u001b[39m mgr\u001b[39m.\u001b[39;49mcopy()\n\u001b[0;32m    232\u001b[0m     new_mgrs\u001b[39m.\u001b[39mappend(mgr)\n\u001b[0;32m    233\u001b[0m \u001b[39mreturn\u001b[39;00m new_mgrs\n",
      "File \u001b[1;32mc:\\Users\\yeong\\miniconda3\\envs\\monit\\lib\\site-packages\\pandas\\core\\internals\\managers.py:587\u001b[0m, in \u001b[0;36mBaseBlockManager.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    584\u001b[0m         res\u001b[39m.\u001b[39m_blklocs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_blklocs\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m    586\u001b[0m \u001b[39mif\u001b[39;00m deep:\n\u001b[1;32m--> 587\u001b[0m     res\u001b[39m.\u001b[39;49m_consolidate_inplace()\n\u001b[0;32m    588\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\Users\\yeong\\miniconda3\\envs\\monit\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1750\u001b[0m, in \u001b[0;36mBlockManager._consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1744\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_consolidate_inplace\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[39m# In general, _consolidate_inplace should only be called via\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m     \u001b[39m#  DataFrame._consolidate_inplace, otherwise we will fail to invalidate\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m     \u001b[39m#  the DataFrame's _item_cache. The exception is for newly-created\u001b[39;00m\n\u001b[0;32m   1748\u001b[0m     \u001b[39m#  BlockManager objects not yet attached to a DataFrame.\u001b[39;00m\n\u001b[0;32m   1749\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_consolidated():\n\u001b[1;32m-> 1750\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks \u001b[39m=\u001b[39m _consolidate(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblocks)\n\u001b[0;32m   1751\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_consolidated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1752\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_known_consolidated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yeong\\miniconda3\\envs\\monit\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2217\u001b[0m, in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   2215\u001b[0m new_blocks: \u001b[39mlist\u001b[39m[Block] \u001b[39m=\u001b[39m []\n\u001b[0;32m   2216\u001b[0m \u001b[39mfor\u001b[39;00m (_can_consolidate, dtype), group_blocks \u001b[39min\u001b[39;00m grouper:\n\u001b[1;32m-> 2217\u001b[0m     merged_blocks, _ \u001b[39m=\u001b[39m _merge_blocks(\n\u001b[0;32m   2218\u001b[0m         \u001b[39mlist\u001b[39;49m(group_blocks), dtype\u001b[39m=\u001b[39;49mdtype, can_consolidate\u001b[39m=\u001b[39;49m_can_consolidate\n\u001b[0;32m   2219\u001b[0m     )\n\u001b[0;32m   2220\u001b[0m     new_blocks \u001b[39m=\u001b[39m extend_blocks(merged_blocks, new_blocks)\n\u001b[0;32m   2221\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(new_blocks)\n",
      "File \u001b[1;32mc:\\Users\\yeong\\miniconda3\\envs\\monit\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2242\u001b[0m, in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[0;32m   2235\u001b[0m new_values: ArrayLike\n\u001b[0;32m   2237\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(blocks[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39mdtype):\n\u001b[0;32m   2238\u001b[0m     \u001b[39m# error: List comprehension has incompatible type List[Union[ndarray,\u001b[39;00m\n\u001b[0;32m   2239\u001b[0m     \u001b[39m# ExtensionArray]]; expected List[Union[complex, generic,\u001b[39;00m\n\u001b[0;32m   2240\u001b[0m     \u001b[39m# Sequence[Union[int, float, complex, str, bytes, generic]],\u001b[39;00m\n\u001b[0;32m   2241\u001b[0m     \u001b[39m# Sequence[Sequence[Any]], SupportsArray]]\u001b[39;00m\n\u001b[1;32m-> 2242\u001b[0m     new_values \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mvstack([b\u001b[39m.\u001b[39;49mvalues \u001b[39mfor\u001b[39;49;00m b \u001b[39min\u001b[39;49;00m blocks])  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   2243\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2244\u001b[0m     bvals \u001b[39m=\u001b[39m [blk\u001b[39m.\u001b[39mvalues \u001b[39mfor\u001b[39;00m blk \u001b[39min\u001b[39;00m blocks]\n",
      "File \u001b[1;32mc:\\Users\\yeong\\miniconda3\\envs\\monit\\lib\\site-packages\\numpy\\core\\shape_base.py:289\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(tup, dtype, casting)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(arrs, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    288\u001b[0m     arrs \u001b[39m=\u001b[39m [arrs]\n\u001b[1;32m--> 289\u001b[0m \u001b[39mreturn\u001b[39;00m _nx\u001b[39m.\u001b[39;49mconcatenate(arrs, \u001b[39m0\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mdtype, casting\u001b[39m=\u001b[39;49mcasting)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 4.58 GiB for an array with shape (38, 16188570) and data type float64"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df_357 = pd.read_csv('./data/senhub/hub_device_357.csv')\n",
    "\n",
    "def  make_df(_df):\n",
    "    \n",
    "    # 데이터 전처리\n",
    "    _df.drop(['_id_x', '_id_y','device_id_y'], axis=1, inplace=True)\n",
    "    _df['updated'] = pd.to_datetime(_df['updated'])\n",
    "    _df.rename(columns={'device_id_x' : 'device_id'}, inplace=True)\n",
    "        \n",
    "    # 날짜 리스트 설정\n",
    "    day_list = _df['updated'].dt.date.unique()\n",
    "    \n",
    "    # 평균값 담을 객체 생성\n",
    "    sensor_mean_list = [0] * 3\n",
    "    hub_mean_list = [0] * 3\n",
    "\n",
    "    # 날짜별 데이터 호출\n",
    "    for day in day_list:\n",
    "        day_df = _df[_df['updated'].dt.date == day]\n",
    "        \n",
    "        # 해당 날짜의 데이터가 없다면 continue를 사용하여 다음 반복으로 넘어갑니다.\n",
    "        if day_df['temperature'].isna().all():\n",
    "            continue\n",
    "        \n",
    "        # 센서 온도 있는 경우에만 뒤의 값으로 보간법 시행\n",
    "        day_df['tem_bfill'] = day_df['tem'].bfill()\n",
    "        # day_df.loc[day_df['temperature'].isnull(), 'tem_bfill'] = None\n",
    "        \n",
    "        # 3일 평균 데이터 갱신\n",
    "        sensor_mean_list.pop(0)\n",
    "        sensor_mean_list.append(day_df['temperature'].mean())\n",
    "        \n",
    "        if not day_df['tem_bfill'].isna().all():\n",
    "            hub_mean_list.pop(0)\n",
    "            hub_mean_list.append(day_df['tem_bfill'].mean())\n",
    "        \n",
    "        # 3일 평균 데이터 가져오기\n",
    "        sensor_not_zero = [i for i in sensor_mean_list if i!=0]\n",
    "        hub_not_zero = [i for i in hub_mean_list if i!=0]\n",
    "        \n",
    "        sensor_mean = np.mean(sensor_not_zero)\n",
    "        hub_mean = np.mean(hub_not_zero)\n",
    "        \n",
    "        # 평균 데이터 컬럼 추가\n",
    "        day_df['sensor_mean'] = sensor_mean * len(day_df)\n",
    "        day_df['hub_mean'] = hub_mean * len(day_df)\n",
    "                \n",
    "        day_df.drop(['device_id', 'days','sex','temperature','humidity','voc','hum','tem'], axis=1, inplace=True)\n",
    "        \n",
    "        # 원본 데이터와 concat\n",
    "        _df = pd.merge(_df, day_df, how='left', on=['updated'])\n",
    "        \n",
    "    # 인덱스 설정\n",
    "    _df.set_index('updated', inplace=True)\n",
    "    \n",
    "    # 이동평균 컬럼 추가\n",
    "    _df['temperature_moving_avg'] = _df['temperature'].rolling(window=1200).mean()\n",
    "    _df['tem_moving_avg'] = _df['tem_bfill'].rolling(window=1200).mean()\n",
    "        \n",
    "    return _df\n",
    "    \n",
    "df_357_after = make_df(df_357)\n",
    "df_357_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.78055339e+08,            nan])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_357_after['sensor_mean'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_plot(_df):\n",
    "    # # 데이터의 최소값과 최대값으로 y축 고정\n",
    "    # ymin = _df['temperature'].min()\n",
    "    # ymax = _df['temperature'].max()\n",
    "\n",
    "    # 시각화 날짜 리스트 설정\n",
    "    day_list = _df['updated'].dt.date.unique()\n",
    "\n",
    "    # 평균값 담을 객체 생성\n",
    "    sensor_mean_list = [0] * 3\n",
    "    hub_mean_list = [0] * 3\n",
    "\n",
    "    # 날짜별 데이터 시각화\n",
    "    for min_day in day_list:\n",
    "        day_df = _df[_df['updated'].dt.date == min_day]\n",
    "        \n",
    "        # 센서 온도 있는 경우에만 뒤의 값으로 보간법 시행\n",
    "        day_df['tem'] = day_df['tem'].bfill()\n",
    "        # day_df.loc[day_df['temperature'].isnull(), 'tem'] = None\n",
    "        \n",
    "        # 해당 날짜의 데이터가 없다면 continue를 사용하여 다음 반복으로 넘어갑니다.\n",
    "        if day_df['temperature'].isna().all():\n",
    "            continue\n",
    "        \n",
    "        # 3일 평균 데이터 갱신\n",
    "        sensor_mean_list.pop(0)\n",
    "        sensor_mean_list.append(day_df['temperature'].mean())\n",
    "        \n",
    "        if not day_df['tem'].isna().all():\n",
    "            hub_mean_list.pop(0)\n",
    "            hub_mean_list.append(day_df['tem'].mean())\n",
    "        \n",
    "        # 3일 평균 데이터 가져오기\n",
    "        sensor_not_zero = [i for i in sensor_mean_list if i!=0]\n",
    "        hub_not_zero = [i for i in hub_mean_list if i!=0]\n",
    "        \n",
    "        sensor_mean = np.mean(sensor_not_zero)\n",
    "        hub_mean = np.mean(hub_not_zero)\n",
    "        \n",
    "        \n",
    "        # 그래프 시각화\n",
    "        fig, ax = plt.subplots(figsize=(10,5))\n",
    "        \n",
    "        # 온도 그래프\n",
    "        ax.plot(day_df['updated'], day_df['temperature'], color='tab:red', label='sensor')\n",
    "        \n",
    "        if not day_df['tem'].isna().all():\n",
    "            ax.plot(day_df['updated'], day_df['tem'], color='tab:green', label='hub')\n",
    "        \n",
    "        # 평균값 그래프\n",
    "        ax.axhline(y=sensor_mean, color='tab:blue', label='sensor_mean')\n",
    "        \n",
    "        if len(hub_not_zero) != 0:\n",
    "            ax.axhline(y=hub_mean, color='tab:purple', label='hub_mean')\n",
    "        \n",
    "        ax.set_xlabel('Time')\n",
    "        ax.set_ylabel('Temperature')\n",
    "        ax.tick_params(axis='y')\n",
    "        ax.legend()\n",
    "        \n",
    "        # y축 범위 설정\n",
    "        # ax.set_ylim(ymin, ymax)\n",
    "\n",
    "        # 시간 형식 설정\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "        \n",
    "        fig.tight_layout()\n",
    "        plt.title(f'Temperature on {str(min_day)}')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. min_age, max_age를 통해 2220, 1416 데이터를 타겟 데이터로 선정하였음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>updated</th>\n",
       "      <th>device_id</th>\n",
       "      <th>days</th>\n",
       "      <th>sex</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>voc</th>\n",
       "      <th>tem</th>\n",
       "      <th>hum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-05-30 22:28:20</td>\n",
       "      <td>1416.0</td>\n",
       "      <td>1520.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3008.0</td>\n",
       "      <td>3911.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-05-30 22:28:21</td>\n",
       "      <td>1416.0</td>\n",
       "      <td>1520.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-05-30 22:28:22</td>\n",
       "      <td>1416.0</td>\n",
       "      <td>1520.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-05-30 22:28:23</td>\n",
       "      <td>1416.0</td>\n",
       "      <td>1520.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-05-30 22:28:24</td>\n",
       "      <td>1416.0</td>\n",
       "      <td>1520.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7214980</th>\n",
       "      <td>2023-08-22 10:37:58</td>\n",
       "      <td>1416.0</td>\n",
       "      <td>1604.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7214981</th>\n",
       "      <td>2023-08-22 10:37:59</td>\n",
       "      <td>1416.0</td>\n",
       "      <td>1604.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7214982</th>\n",
       "      <td>2023-08-22 10:38:00</td>\n",
       "      <td>1416.0</td>\n",
       "      <td>1604.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7214983</th>\n",
       "      <td>2023-08-22 10:38:01</td>\n",
       "      <td>1416.0</td>\n",
       "      <td>1604.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2956.0</td>\n",
       "      <td>5401.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2475.0</td>\n",
       "      <td>7496.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7214984</th>\n",
       "      <td>2023-08-22 10:38:01</td>\n",
       "      <td>1416.0</td>\n",
       "      <td>1604.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2956.0</td>\n",
       "      <td>5401.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2475.0</td>\n",
       "      <td>7496.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7214985 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    updated  device_id    days  sex  temperature  humidity  \\\n",
       "0       2023-05-30 22:28:20     1416.0  1520.0  1.0       3008.0    3911.0   \n",
       "1       2023-05-30 22:28:21     1416.0  1520.0  1.0          NaN       NaN   \n",
       "2       2023-05-30 22:28:22     1416.0  1520.0  1.0          NaN       NaN   \n",
       "3       2023-05-30 22:28:23     1416.0  1520.0  1.0          NaN       NaN   \n",
       "4       2023-05-30 22:28:24     1416.0  1520.0  1.0          NaN       NaN   \n",
       "...                     ...        ...     ...  ...          ...       ...   \n",
       "7214980 2023-08-22 10:37:58     1416.0  1604.0  1.0          NaN       NaN   \n",
       "7214981 2023-08-22 10:37:59     1416.0  1604.0  1.0          NaN       NaN   \n",
       "7214982 2023-08-22 10:38:00     1416.0  1604.0  1.0          NaN       NaN   \n",
       "7214983 2023-08-22 10:38:01     1416.0  1604.0  1.0       2956.0    5401.0   \n",
       "7214984 2023-08-22 10:38:01     1416.0  1604.0  1.0       2956.0    5401.0   \n",
       "\n",
       "         voc     tem     hum  \n",
       "0        0.0     NaN     NaN  \n",
       "1        NaN     NaN     NaN  \n",
       "2        NaN     NaN     NaN  \n",
       "3        NaN     NaN     NaN  \n",
       "4        NaN     NaN     NaN  \n",
       "...      ...     ...     ...  \n",
       "7214980  NaN     NaN     NaN  \n",
       "7214981  NaN     NaN     NaN  \n",
       "7214982  NaN     NaN     NaN  \n",
       "7214983  0.0  2475.0  7496.0  \n",
       "7214984  0.0  2475.0  7496.0  \n",
       "\n",
       "[7214985 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "min_df = pd.read_csv('./data/senhub/hub_device_2220.csv')\n",
    "max_df = pd.read_csv('./data/senhub/hub_device_1416.csv')\n",
    "\n",
    "min_df.drop(['_id_x', '_id_y','device_id_y'], axis=1, inplace=True)\n",
    "max_df.drop(['_id_x', '_id_y','device_id_y'], axis=1, inplace=True)\n",
    "\n",
    "min_df['updated'] = pd.to_datetime(min_df['updated'])\n",
    "max_df['updated'] = pd.to_datetime(max_df['updated'])\n",
    "\n",
    "min_df.rename(columns={'device_id_x' : 'device_id'})\n",
    "max_df.rename(columns={'device_id_x' : 'device_id'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 겹치는 그래프가 없네..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터 수량 많은 아기(357)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_357 = pd.read_csv('./data/senhub/hub_device_357.csv')\n",
    "make_df(df_357)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 시각화 그래프 함수 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def  make_df(_df):\n",
    "    \n",
    "    # 데이터 전처리\n",
    "    _df.drop(['_id_x', '_id_y','device_id_y'], axis=1, inplace=True)\n",
    "    _df['updated'] = pd.to_datetime(_df['updated'])\n",
    "    _df.rename(columns={'device_id_x' : 'device_id'})\n",
    "    \n",
    "    # 날짜 리스트 설정\n",
    "    day_list = _df['updated'].dt.date.unique()\n",
    "    \n",
    "    # 평균값 담을 객체 생성\n",
    "    sensor_mean_list = [0] * 3\n",
    "    hub_mean_list = [0] * 3\n",
    "\n",
    "    # 날짜별 데이터 호출\n",
    "    for day in day_list:\n",
    "        day_df = _df[_df['updated'].dt.date == day]\n",
    "        \n",
    "        # 해당 날짜의 데이터가 없다면 continue를 사용하여 다음 반복으로 넘어갑니다.\n",
    "        if day_df['temperature'].isna().all():\n",
    "            continue\n",
    "        \n",
    "        # 센서 온도 있는 경우에만 뒤의 값으로 보간법 시행\n",
    "        day_df['tem'] = day_df['tem'].bfill()\n",
    "        day_df.loc[day_df['temperature'].isnull(), 'tem'] = None\n",
    "        \n",
    "        # 3일 평균 데이터 갱신\n",
    "        sensor_mean_list.pop(0)\n",
    "        sensor_mean_list.append(day_df['temperature'].mean())\n",
    "        \n",
    "        if not day_df['tem'].isna().all():\n",
    "            hub_mean_list.pop(0)\n",
    "            hub_mean_list.append(day_df['tem'].mean())\n",
    "        \n",
    "        # 3일 평균 데이터 가져오기\n",
    "        sensor_not_zero = [i for i in sensor_mean_list if i!=0]\n",
    "        hub_not_zero = [i for i in hub_mean_list if i!=0]\n",
    "        \n",
    "        sensor_mean = np.mean(sensor_not_zero)\n",
    "        hub_mean = np.mean(hub_not_zero)\n",
    "        \n",
    "        # 평균 데이터 컬럼 추가\n",
    "        day_df['sensor_mean'] = sensor_mean * len(day_df)\n",
    "        day_df['hub_mean'] = hub_mean * len(day_df)\n",
    "        \n",
    "        # 이동평균 컬럼 추가\n",
    "        day_df['temperature_moving_avg'] = day_df['temperature'].rolling(window=1200).mean()\n",
    "        day_df['tem_moving_avg'] = day_df['tem'].rolling(window=1200).mean()\n",
    "        \n",
    "        _df.drop(['tem'], axis=1, inplace=True)\n",
    "        day_df.drop(['days','sex','temperature','humidity','voc','hum'], axis=1)\n",
    "        \n",
    "        # 원본 데이터와 concat\n",
    "        _df = pd.merge(_df, day_df, how='left', on=['device_id','updated'])\n",
    "        \n",
    "        break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. min_age, max_age를 통해 2220, 1416 데이터를 타겟 데이터로 선정하였음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>updated</th>\n",
       "      <th>device_id</th>\n",
       "      <th>days</th>\n",
       "      <th>sex</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>voc</th>\n",
       "      <th>tem</th>\n",
       "      <th>hum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-05-30 22:28:20</td>\n",
       "      <td>1416.0</td>\n",
       "      <td>1520.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3008.0</td>\n",
       "      <td>3911.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-05-30 22:28:21</td>\n",
       "      <td>1416.0</td>\n",
       "      <td>1520.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-05-30 22:28:22</td>\n",
       "      <td>1416.0</td>\n",
       "      <td>1520.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-05-30 22:28:23</td>\n",
       "      <td>1416.0</td>\n",
       "      <td>1520.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-05-30 22:28:24</td>\n",
       "      <td>1416.0</td>\n",
       "      <td>1520.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7214980</th>\n",
       "      <td>2023-08-22 10:37:58</td>\n",
       "      <td>1416.0</td>\n",
       "      <td>1604.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7214981</th>\n",
       "      <td>2023-08-22 10:37:59</td>\n",
       "      <td>1416.0</td>\n",
       "      <td>1604.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7214982</th>\n",
       "      <td>2023-08-22 10:38:00</td>\n",
       "      <td>1416.0</td>\n",
       "      <td>1604.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7214983</th>\n",
       "      <td>2023-08-22 10:38:01</td>\n",
       "      <td>1416.0</td>\n",
       "      <td>1604.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2956.0</td>\n",
       "      <td>5401.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2475.0</td>\n",
       "      <td>7496.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7214984</th>\n",
       "      <td>2023-08-22 10:38:01</td>\n",
       "      <td>1416.0</td>\n",
       "      <td>1604.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2956.0</td>\n",
       "      <td>5401.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2475.0</td>\n",
       "      <td>7496.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7214985 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    updated  device_id    days  sex  temperature  humidity  \\\n",
       "0       2023-05-30 22:28:20     1416.0  1520.0  1.0       3008.0    3911.0   \n",
       "1       2023-05-30 22:28:21     1416.0  1520.0  1.0          NaN       NaN   \n",
       "2       2023-05-30 22:28:22     1416.0  1520.0  1.0          NaN       NaN   \n",
       "3       2023-05-30 22:28:23     1416.0  1520.0  1.0          NaN       NaN   \n",
       "4       2023-05-30 22:28:24     1416.0  1520.0  1.0          NaN       NaN   \n",
       "...                     ...        ...     ...  ...          ...       ...   \n",
       "7214980 2023-08-22 10:37:58     1416.0  1604.0  1.0          NaN       NaN   \n",
       "7214981 2023-08-22 10:37:59     1416.0  1604.0  1.0          NaN       NaN   \n",
       "7214982 2023-08-22 10:38:00     1416.0  1604.0  1.0          NaN       NaN   \n",
       "7214983 2023-08-22 10:38:01     1416.0  1604.0  1.0       2956.0    5401.0   \n",
       "7214984 2023-08-22 10:38:01     1416.0  1604.0  1.0       2956.0    5401.0   \n",
       "\n",
       "         voc     tem     hum  \n",
       "0        0.0     NaN     NaN  \n",
       "1        NaN     NaN     NaN  \n",
       "2        NaN     NaN     NaN  \n",
       "3        NaN     NaN     NaN  \n",
       "4        NaN     NaN     NaN  \n",
       "...      ...     ...     ...  \n",
       "7214980  NaN     NaN     NaN  \n",
       "7214981  NaN     NaN     NaN  \n",
       "7214982  NaN     NaN     NaN  \n",
       "7214983  0.0  2475.0  7496.0  \n",
       "7214984  0.0  2475.0  7496.0  \n",
       "\n",
       "[7214985 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "min_df = pd.read_csv('./data/senhub/hub_device_2220.csv')\n",
    "max_df = pd.read_csv('./data/senhub/hub_device_1416.csv')\n",
    "\n",
    "min_df.drop(['_id_x', '_id_y','device_id_y'], axis=1, inplace=True)\n",
    "max_df.drop(['_id_x', '_id_y','device_id_y'], axis=1, inplace=True)\n",
    "\n",
    "min_df['updated'] = pd.to_datetime(min_df['updated'])\n",
    "max_df['updated'] = pd.to_datetime(max_df['updated'])\n",
    "\n",
    "min_df.rename(columns={'device_id_x' : 'device_id'})\n",
    "max_df.rename(columns={'device_id_x' : 'device_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yeong\\AppData\\Local\\Temp\\ipykernel_4892\\3830756969.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  day_df['tem'] = day_df['tem'].bfill()\n",
      "c:\\Users\\yeong\\miniconda3\\envs\\monit\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\yeong\\miniconda3\\envs\\monit\\lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\yeong\\AppData\\Local\\Temp\\ipykernel_4892\\3830756969.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  day_df['sensor_mean'] = sensor_mean * len(day_df)\n",
      "C:\\Users\\yeong\\AppData\\Local\\Temp\\ipykernel_4892\\3830756969.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  day_df['hub_mean'] = hub_mean * len(day_df)\n",
      "C:\\Users\\yeong\\AppData\\Local\\Temp\\ipykernel_4892\\3830756969.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  day_df['temperature_moving_avg'] = day_df['temperature'].rolling(window=1200).mean()\n",
      "C:\\Users\\yeong\\AppData\\Local\\Temp\\ipykernel_4892\\3830756969.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  day_df['tem_moving_avg'] = day_df['tem'].rolling(window=1200).mean()\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'device_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4892\\2695618311.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n",
      "\u001b[0;32m      1\u001b[0m \u001b[0mdf_357\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data/senhub/hub_device_357.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmake_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_357\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4892\\3830756969.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(_df)\u001b[0m\n",
      "\u001b[0;32m     55\u001b[0m         \u001b[0m_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tem'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m     56\u001b[0m         \u001b[0mday_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'days'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'sex'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'temperature'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'humidity'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'voc'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'hum'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m     58\u001b[0m         \u001b[1;31m# 원본 데이터와 concat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m---> 59\u001b[1;33m         \u001b[0m_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mday_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'device_id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'updated'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\yeong\\miniconda3\\envs\\monit\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n",
      "\u001b[0;32m    165\u001b[0m             \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    166\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    167\u001b[0m         )\n",
      "\u001b[0;32m    168\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m--> 169\u001b[1;33m         op = _MergeOperation(\n",
      "\u001b[0m\u001b[0;32m    170\u001b[0m             \u001b[0mleft_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    171\u001b[0m             \u001b[0mright_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    172\u001b[0m             \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1;32mc:\\Users\\yeong\\miniconda3\\envs\\monit\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n",
      "\u001b[0;32m    787\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    788\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    789\u001b[0m             \u001b[0mleft_drop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    790\u001b[0m             \u001b[0mright_drop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m--> 791\u001b[1;33m         ) = self._get_merge_keys()\n",
      "\u001b[0m\u001b[0;32m    792\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    793\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mleft_drop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    794\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_labels_or_levels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft_drop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1;32mc:\\Users\\yeong\\miniconda3\\envs\\monit\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[0;32m   1265\u001b[0m                         \u001b[1;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   1266\u001b[0m                         \u001b[1;31m#  the latter of which will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   1267\u001b[0m                         \u001b[0mrk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   1268\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m-> 1269\u001b[1;33m                             \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1270\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   1271\u001b[0m                             \u001b[1;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   1272\u001b[0m                             \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1;32mc:\\Users\\yeong\\miniconda3\\envs\\monit\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, axis)\u001b[0m\n",
      "\u001b[0;32m   1840\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   1841\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   1842\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   1843\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m-> 1844\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1845\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   1846\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   1847\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1;31mKeyError\u001b[0m: 'device_id'"
     ]
    }
   ],
   "source": [
    "df_357 = pd.read_csv('./data/senhub/hub_device_357.csv')\n",
    "make_df(df_357)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_plot(df_357)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
